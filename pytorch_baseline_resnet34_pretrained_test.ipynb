{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f4de42",
   "metadata": {},
   "source": [
    "# dAiv AI_Competition[2024]_Pro Baseline for PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9142930",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "bd45d5b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:07.722822Z",
     "start_time": "2024-10-18T08:40:04.076723Z"
    }
   },
   "source": [
    "from os import path, rename, mkdir, listdir\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, utils, models\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datasets.utils.tqdm = tqdm\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "4049b434",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "id": "e475e84e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:08.333639Z",
     "start_time": "2024-10-18T08:40:07.753449Z"
    }
   },
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 18 08:40:07 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   41C    P0    34W / 250W |    679MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P100-PCIE...  On   | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   41C    P0    31W / 250W |  15369MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla P100-PCIE...  On   | 00000000:07:00.0 Off |                    0 |\r\n",
      "| N/A   43C    P0    28W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla P100-PCIE...  On   | 00000000:08:00.0 Off |                    0 |\r\n",
      "| N/A   39C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  Tesla P100-PCIE...  On   | 00000000:0C:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    25W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  Tesla P100-PCIE...  On   | 00000000:0D:00.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  Tesla P100-PCIE...  On   | 00000000:0E:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  Tesla P100-PCIE...  On   | 00000000:0F:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    31W / 250W |   4383MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A      9377      C   ...on08/anaconda3/bin/python    15367MiB |\r\n",
      "|    7   N/A  N/A     19896      C   ...on03/anaconda3/bin/python     4381MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0d2df737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:09.261409Z",
     "start_time": "2024-10-18T08:40:08.938805Z"
    }
   },
   "source": [
    "# Set CUDA Device Number 0~7\n",
    "DEVICE_NUM = 5\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE_NUM)\n",
    "    device = torch.device(\"cuda\")\n",
    "print(\"INFO: Using device -\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device - cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "85bc3d0f",
   "metadata": {},
   "source": [
    "## Load DataSets"
   ]
  },
  {
   "cell_type": "code",
   "id": "56b28aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:09.775335Z",
     "start_time": "2024-10-18T08:40:09.333579Z"
    }
   },
   "source": [
    "from typing import Callable, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class ImageDataset(datasets.ImageFolder):\n",
    "    download_url = \"https://daiv-cnu.duckdns.org/contest/ai_competition[2024]_pro/dataset/archive.zip\"\n",
    "    random_state = 20241028\n",
    "\n",
    "    def __init__(\n",
    "            self, root: str, force_download: bool = True,\n",
    "            train: bool = False, valid: bool = False, split_ratio: float = 0.8,\n",
    "            test: bool = False, unlabeled: bool = False,\n",
    "            transform: Optional[Callable] = None, target_transform: Optional[Callable] = None\n",
    "    ):\n",
    "        self.download(root, force=force_download)  # Download Dataset from server\n",
    "\n",
    "        if train or valid:  # Set-up directory\n",
    "            root = path.join(root, \"train\")\n",
    "        else:\n",
    "            root = path.join(root, \"test\" if test else \"unlabeled\" if unlabeled else None)\n",
    "\n",
    "        # Initialize ImageFolder\n",
    "        super().__init__(root=root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        if train or valid:  # Split Train and Validation Set\n",
    "            seperated = train_test_split(\n",
    "                self.samples, self.targets, test_size=1-split_ratio, stratify=self.targets, random_state=self.random_state\n",
    "            )\n",
    "            self.samples, self.targets = (seperated[0], seperated[2]) if train else (seperated[1], seperated[3])\n",
    "            self.imgs = self.samples\n",
    "\n",
    "    @classmethod\n",
    "    def download(cls, root: str, force: bool = False):\n",
    "        if force or not path.isfile(path.join(root, \"archive.zip\")):\n",
    "            # Download and Extract Dataset\n",
    "            datasets.utils.download_and_extract_archive(cls.download_url, download_root=root, extract_root=root, filename=\"archive.zip\")\n",
    "            \n",
    "            # Arrange Dataset Directory\n",
    "            for target_dir in [path.join(root, \"test\"), path.join(root, \"unlabeled\")]:\n",
    "                for file in listdir(target_dir):\n",
    "                    mkdir(path.join(target_dir, file.replace(\".jpg\", \"\")))\n",
    "                    rename(path.join(target_dir, file), path.join(target_dir, file.replace(\".jpg\", \"\"), file))\n",
    "\n",
    "            print(\"INFO: Dataset archive downloaded and extracted.\")\n",
    "        else:\n",
    "            print(\"INFO: Dataset archive found in the root directory. Skipping download.\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset Initialization",
   "id": "b419ce2cb5914ac5"
  },
  {
   "cell_type": "code",
   "id": "e1489d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:09.852120Z",
     "start_time": "2024-10-18T08:40:09.847325Z"
    }
   },
   "source": [
    "# Image Resizing and Tensor Conversion\n",
    "IMG_SIZE = (256, 256)\n",
    "IMG_NORM = dict(  # ImageNet Normalization\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "resizer = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),  # Resize Image\n",
    "    transforms.ToTensor(),  # Convert Image to Tensor\n",
    "    transforms.Normalize(**IMG_NORM)  # Normalization\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "55933cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:09.989179Z",
     "start_time": "2024-10-18T08:40:09.890566Z"
    }
   },
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "train_dataset = ImageDataset(root=DATA_ROOT, force_download=False, train=True, transform=resizer)\n",
    "valid_dataset = ImageDataset(root=DATA_ROOT, force_download=False, valid=True, transform=resizer)\n",
    "\n",
    "test_dataset = ImageDataset(root=DATA_ROOT, force_download=False, test=True, transform=resizer)\n",
    "unlabeled_dataset = ImageDataset(root=DATA_ROOT, force_download=False, unlabeled=True, transform=resizer)\n",
    "\n",
    "print(f\"INFO: Dataset loaded successfully. Number of samples - Train({len(train_dataset)}), Valid({len(valid_dataset)}), Test({len(test_dataset)}), Unlabeled({len(unlabeled_dataset)})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Dataset loaded successfully. Number of samples - Train(7478), Valid(1870), Test(1110), Unlabeled(380)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualize Dataset Distribution\n",
    "    - for checking..."
   ],
   "id": "5b6fe305cb5b234b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:10.019923Z",
     "start_time": "2024-10-18T08:40:10.015865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "def dist_visualizer(dataset, title: str):\n",
    "    counter = Counter(dataset.targets)\n",
    "    labels, values = zip(*sorted(counter.items()))\n",
    "\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.bar(labels, values)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ],
   "id": "2a012af140f88d5d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:10.069473Z",
     "start_time": "2024-10-18T08:40:10.064839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Label Check\n",
    "for i, label in zip(range(5), train_dataset.targets):\n",
    "    print(i, \"-\", train_dataset.classes[label])"
   ],
   "id": "ba2d5dcc2de29df3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 050.Pelagic_Cormorant\n",
      "1 - 020.Leonberger\n",
      "2 - 104.Black_capped_Vireo\n",
      "3 - 020.Leonberger\n",
      "4 - 009.Siamese\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:10.158009Z",
     "start_time": "2024-10-18T08:40:10.098984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Check\n",
    "for i, image in zip(range(2), train_dataset.samples):\n",
    "    print(i, \"-\", *train_dataset[i], image[0])"
   ],
   "id": "d8c7a2e166c6556a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - tensor([[[ 0.5364,  0.5536,  0.5536,  ...,  0.7419,  0.7077,  0.7077],\n",
      "         [ 0.5364,  0.5536,  0.5536,  ...,  0.7419,  0.7077,  0.7077],\n",
      "         [ 0.5536,  0.5536,  0.5536,  ...,  0.7419,  0.7248,  0.7248],\n",
      "         ...,\n",
      "         [ 1.3070,  1.1872,  1.1358,  ...,  0.9988,  1.1015,  0.8104],\n",
      "         [ 1.2043,  1.1872,  1.1015,  ...,  0.7419,  0.6392,  0.4851],\n",
      "         [ 1.0844,  1.1187,  1.0673,  ...,  0.7248,  0.6734,  1.0331]],\n",
      "\n",
      "        [[ 0.3978,  0.4153,  0.4328,  ...,  0.5028,  0.4678,  0.4328],\n",
      "         [ 0.3978,  0.4153,  0.4153,  ...,  0.5028,  0.4853,  0.4503],\n",
      "         [ 0.3803,  0.3803,  0.4153,  ...,  0.5028,  0.4853,  0.4503],\n",
      "         ...,\n",
      "         [ 1.0455,  0.9230,  0.8880,  ...,  0.7829,  0.8704,  0.5553],\n",
      "         [ 0.9755,  0.9580,  0.9055,  ...,  0.5553,  0.3627,  0.1176],\n",
      "         [ 0.8529,  0.9055,  0.8880,  ...,  0.5378,  0.3803,  0.6779]],\n",
      "\n",
      "        [[ 0.2348,  0.2348,  0.2522,  ...,  0.3045,  0.2522,  0.1999],\n",
      "         [ 0.2173,  0.2348,  0.2348,  ...,  0.3045,  0.2522,  0.1999],\n",
      "         [ 0.2173,  0.2173,  0.1999,  ...,  0.3219,  0.2696,  0.2173],\n",
      "         ...,\n",
      "         [ 1.0191,  0.8971,  0.8971,  ...,  0.3916,  0.5136,  0.2173],\n",
      "         [ 0.9494,  0.9494,  0.9319,  ...,  0.2871,  0.1651, -0.1835],\n",
      "         [ 0.8274,  0.9145,  0.9319,  ...,  0.3568,  0.1999,  0.3045]]]) 50 ./data/train/050.Pelagic_Cormorant/016.jpg\n",
      "1 - tensor([[[-0.4226, -0.5938, -0.8678,  ..., -0.3369, -0.4568, -0.5253],\n",
      "         [-0.3883, -0.5596, -0.8335,  ..., -0.3027, -0.4226, -0.4911],\n",
      "         [-0.3541, -0.4739, -0.7822,  ..., -0.2856, -0.4054, -0.4739],\n",
      "         ...,\n",
      "         [-0.3541, -0.4739, -0.5253,  ..., -0.9877, -0.9705, -0.9877],\n",
      "         [-0.4397, -0.5082, -0.5253,  ..., -0.9877, -1.0048, -1.0562],\n",
      "         [-0.5082, -0.5424, -0.5253,  ..., -0.9192, -0.7479, -0.7822]],\n",
      "\n",
      "        [[-0.0749, -0.0749, -0.1450,  ..., -0.1275, -0.2500, -0.3200],\n",
      "         [-0.0574, -0.0749, -0.0924,  ..., -0.0924, -0.2325, -0.3025],\n",
      "         [-0.0224, -0.0399, -0.0749,  ..., -0.0749, -0.1975, -0.2850],\n",
      "         ...,\n",
      "         [-0.2675, -0.3901, -0.4426,  ..., -0.3550, -0.3375, -0.4426],\n",
      "         [-0.3375, -0.4251, -0.4601,  ..., -0.4076, -0.4076, -0.4951],\n",
      "         [-0.4076, -0.4601, -0.4601,  ..., -0.4076, -0.3375, -0.4251]],\n",
      "\n",
      "        [[ 0.0431, -0.1138, -0.6018,  ...,  0.1651,  0.0605, -0.0267],\n",
      "         [ 0.0779, -0.1138, -0.5495,  ...,  0.1825,  0.0779, -0.0267],\n",
      "         [ 0.1128, -0.0615, -0.4624,  ...,  0.2173,  0.0779, -0.0092],\n",
      "         ...,\n",
      "         [-0.0441, -0.1487, -0.2532,  ..., -0.9504, -0.8633, -0.8110],\n",
      "         [-0.1312, -0.1835, -0.2358,  ..., -0.8981, -0.8458, -0.8633],\n",
      "         [-0.1835, -0.2010, -0.2184,  ..., -0.8284, -0.6367, -0.7064]]]) 20 ./data/train/020.Leonberger/162.jpg\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:10.664847Z",
     "start_time": "2024-10-18T08:40:10.179370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Distribution\n",
    "dist_visualizer(train_dataset, \"Train Dataset Distribution\")\n",
    "dist_visualizer(valid_dataset, \"Valid Dataset Distribution\")"
   ],
   "id": "c16ee12b11a6719",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "7b34674f",
   "metadata": {},
   "source": [
    "## Data Augmentation if needed"
   ]
  },
  {
   "cell_type": "code",
   "id": "7ced1da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:10.769818Z",
     "start_time": "2024-10-18T08:40:10.765873Z"
    }
   },
   "source": [
    "ROTATE_ANGLE = 20\n",
    "COLOR_TRANSFORM = 0.1"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "268d5c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:10.803571Z",
     "start_time": "2024-10-18T08:40:10.799993Z"
    }
   },
   "source": [
    "augmenter = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(ROTATE_ANGLE),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=COLOR_TRANSFORM, contrast=COLOR_TRANSFORM,\n",
    "        saturation=COLOR_TRANSFORM, hue=COLOR_TRANSFORM\n",
    "    ),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0), ratio=(0.75, 1.333)),\n",
    "    resizer\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "efd6c21a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:10.951898Z",
     "start_time": "2024-10-18T08:40:10.907236Z"
    }
   },
   "source": [
    "train_dataset = ImageDataset(root=DATA_ROOT, force_download=False, train=True, transform=augmenter)\n",
    "\n",
    "print(f\"INFO: Train dataset has been overridden with augmented state. Number of samples - Train({len(train_dataset)})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Train dataset has been overridden with augmented state. Number of samples - Train(7478)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "0ccaf990",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5db3d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:11.007628Z",
     "start_time": "2024-10-18T08:40:11.003828Z"
    }
   },
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 128"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "caf78698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:11.072407Z",
     "start_time": "2024-10-18T08:40:11.065161Z"
    }
   },
   "source": [
    "MULTI_PROCESSING = True  # Set False if DataLoader is causing issues\n",
    "\n",
    "from platform import system\n",
    "if MULTI_PROCESSING and system() != \"Windows\":  # Multiprocess data loading is not supported on Windows\n",
    "    import multiprocessing\n",
    "    cpu_cores = multiprocessing.cpu_count()\n",
    "    print(f\"INFO: Number of CPU cores - {cpu_cores}\")\n",
    "else:\n",
    "    cpu_cores = 0\n",
    "    print(\"INFO: Using DataLoader without multi-processing.\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=cpu_cores)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=cpu_cores)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=cpu_cores)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=cpu_cores)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Number of CPU cores - 48\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "d3220e37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:11.110305Z",
     "start_time": "2024-10-18T08:40:11.106434Z"
    }
   },
   "source": [
    "# Image Visualizer\n",
    "def imshow(image_list, mean=IMG_NORM['mean'], std=IMG_NORM['std']):\n",
    "    np_image = np.array(image_list).transpose((1, 2, 0))\n",
    "    de_norm_image = np_image * std + mean\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(de_norm_image)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "566c71c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:11.160882Z",
     "start_time": "2024-10-18T08:40:11.157199Z"
    }
   },
   "source": [
    "# images, targets = next(iter(train_loader))\n",
    "# grid_images = utils.make_grid(images, nrow=8, padding=10)\n",
    "# imshow(grid_images)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "e26620dd",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:11.196143Z",
     "start_time": "2024-10-18T08:40:11.192317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class GradientReversal(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_grl):\n",
    "        ctx.lambda_grl = lambda_grl\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.lambda_grl, None\n"
   ],
   "id": "d9c1837d01463a4",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "230c184a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:11.246032Z",
     "start_time": "2024-10-18T08:40:11.241179Z"
    }
   },
   "source": [
    "class SecondMaxLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.clone()\n",
    "        max_val, max_idx = torch.max(x, dim=1, keepdim=True)\n",
    "        x.scatter_(1, max_idx, 1e-12)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "ca47ef1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:11.284790Z",
     "start_time": "2024-10-18T08:40:11.277159Z"
    }
   },
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, input_channel: int, output_channel: int, adaptive_pool_size: int, img_size: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.multiple_output = False\n",
    "\n",
    "        # 특징 추출기 (ResNet 백본)\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        self.fc_size = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(self.fc_size, adaptive_pool_size)\n",
    "\n",
    "        # 도메인 분류기 - 복잡한 도메인 분류를 위한 다층 퍼셉트론(MLP)\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(adaptive_pool_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        # 출력 레이어 - 최종 예측을 위한 메인 분류기\n",
    "        self.classifier = nn.Linear(adaptive_pool_size, num_classes)\n",
    "\n",
    "        # 멀티라벨 분류를 위한 보조 분류기 (필요할 경우 사용)\n",
    "        self.secondary = SecondMaxLayer()\n",
    "\n",
    "    def toggle_multilabel(self, multi_label: bool | None = None):\n",
    "        \"\"\"싱글 라벨과 멀티 라벨 분류 사이를 전환하는 함수.\"\"\"\n",
    "        if isinstance(multi_label, bool):\n",
    "            self.multiple_output = multi_label\n",
    "        else:\n",
    "            self.multiple_output = not self.multiple_output\n",
    "\n",
    "    def forward(self, x, lambda_grl=1.0):\n",
    "        # ResNet을 통한 특징 추출\n",
    "        extracted = self.resnet(x)\n",
    "    \n",
    "        # 메인 분류기의 출력\n",
    "        out = self.classifier(extracted)\n",
    "    \n",
    "        # GRL 적용 후 도메인 분류기 통과\n",
    "        reversed_feature = GradientReversal.apply(extracted, lambda_grl)\n",
    "        domain = torch.sigmoid(self.domain_classifier(reversed_feature))\n",
    "    \n",
    "        # 멀티라벨 출력이 활성화된 경우\n",
    "        if self.multiple_output:\n",
    "            return domain, out, self.secondary(out)\n",
    "    \n",
    "        # 도메인과 메인 분류기 출력 반환\n",
    "        return domain, out"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "7de92fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:11.447500Z",
     "start_time": "2024-10-18T08:40:11.444109Z"
    }
   },
   "source": [
    "CLASS_LABELS = len(train_dataset.classes)\n",
    "\n",
    "MODEL_PARAMS = dict(\n",
    "    input_channel=3, output_channel=64, adaptive_pool_size=512,\n",
    "    img_size=IMG_SIZE[0], num_classes=CLASS_LABELS\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "81ca0fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:14.539989Z",
     "start_time": "2024-10-18T08:40:11.456779Z"
    }
   },
   "source": [
    "# Initialize Model\n",
    "model = ImageClassifier(**MODEL_PARAMS)\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared_hdd/rnoro5122/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/shared_hdd/rnoro5122/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (domain_classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=120, bias=True)\n",
       "  (secondary): SecondMaxLayer()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "17163e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:14.583928Z",
     "start_time": "2024-10-18T08:40:14.578584Z"
    }
   },
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "e3bee1b6",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "f722e10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:14.648586Z",
     "start_time": "2024-10-18T08:40:14.641015Z"
    }
   },
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Interactive Loss Plot Update\n",
    "def create_plot():\n",
    "    losses = []\n",
    "\n",
    "    # Enable Interactive Mode\n",
    "    plt.ion()\n",
    "\n",
    "    # Loss Plot Setting\n",
    "    fig, ax = plt.subplots(figsize=(6, 2))\n",
    "    line, = ax.plot(losses)\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Cross Entropy Loss\")\n",
    "\n",
    "    # Display Plot\n",
    "    plot = widgets.Output()\n",
    "    display(plot)\n",
    "\n",
    "    def update_plot(new_loss):\n",
    "        losses.append(new_loss.item())\n",
    "        line.set_ydata(losses)\n",
    "        line.set_xdata(range(len(losses)))\n",
    "        ax.relim()\n",
    "        ax.autoscale_view()\n",
    "        with plot:\n",
    "            plot.clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "    return update_plot"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "4cdee4bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:40:14.680785Z",
     "start_time": "2024-10-18T08:40:14.677897Z"
    }
   },
   "source": [
    "# Set Epoch Count\n",
    "num_epochs = 10"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "d5bf15c5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-18T08:40:14.755237Z"
    }
   },
   "source": [
    "train_length, valid_length = map(len, (train_loader, valid_loader))\n",
    "unlabeled_length = len(unlabeled_loader)\n",
    "\n",
    "# 손실 함수 정의\n",
    "domain_criterion = nn.BCELoss()  # 도메인 분류 손실 함수\n",
    "\n",
    "epochs = tqdm(range(num_epochs), desc=\"Running Epochs\")\n",
    "with (tqdm(total=train_length, desc=\"Training\") as train_progress,\n",
    "      tqdm(total=valid_length, desc=\"Validation\") as valid_progress):  # Set up Progress Bars\n",
    "    update = create_plot()  # Create Loss Plot\n",
    "\n",
    "    for epoch in epochs:\n",
    "        train_progress.reset(total=train_length)\n",
    "        valid_progress.reset(total=valid_length)\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        model.toggle_multilabel(False)\n",
    "\n",
    "        unlabeled_iter = iter(unlabeled_loader)  # 타겟 도메인 데이터 로더의 이터레이터 생성\n",
    "\n",
    "        for i, (inputs_source, targets_source) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 소스 도메인 데이터 설정\n",
    "            inputs_source, targets_source = inputs_source.to(device), targets_source.to(device)\n",
    "            domain_label_source = torch.zeros(inputs_source.size(0), 1).to(device)  # 소스 도메인 레이블: 0\n",
    "\n",
    "            # 타겟 도메인 데이터 가져오기\n",
    "            try:\n",
    "                inputs_target, _ = next(unlabeled_iter)  # 타겟 도메인 데이터 가져오기, 레이블은 없음\n",
    "            except StopIteration:\n",
    "                unlabeled_iter = iter(unlabeled_loader)\n",
    "                inputs_target, _ = next(unlabeled_iter)\n",
    "            inputs_target = inputs_target.to(device)\n",
    "            domain_label_target = torch.ones(inputs_target.size(0), 1).to(device)  # 타겟 도메인 레이블: 1\n",
    "\n",
    "            # lambda_grl 값 설정 (필요에 따라 조정하거나 스케줄링 가능)\n",
    "            lambda_grl = 1.0\n",
    "\n",
    "            # 모델 출력 계산\n",
    "            # 소스 도메인 데이터에서 분류와 도메인 분류 출력\n",
    "            domain_outputs_source, outputs_source = model(inputs_source, lambda_grl)\n",
    "            # 타겟 도메인 데이터에서 도메인 분류 출력 (레이블 없음)\n",
    "            domain_outputs_target, _ = model(inputs_target, lambda_grl)\n",
    "\n",
    "            # 손실 함수 계산\n",
    "            # 분류 손실 (소스 도메인 데이터에 대해서만)\n",
    "            classification_loss = criterion(outputs_source, targets_source)\n",
    "\n",
    "            # 도메인 분류 손실 (소스와 타겟 도메인 모두)\n",
    "            domain_outputs = torch.cat([domain_outputs_source, domain_outputs_target], dim=0)\n",
    "            domain_labels = torch.cat([domain_label_source, domain_label_target], dim=0)\n",
    "            domain_classification_loss = domain_criterion(domain_outputs, domain_labels)\n",
    "\n",
    "            # 총 손실 계산 (분류 손실 + 도메인 분류 손실)\n",
    "            loss = classification_loss + domain_classification_loss\n",
    "\n",
    "            # 역전파 및 옵티마이저 스텝\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # # 도메인 분류 정확도 계산\n",
    "            # domain_preds = (domain_outputs >= 0.5).float()\n",
    "            # domain_acc = (domain_preds == domain_labels).sum().item() / domain_labels.size(0)\n",
    "\n",
    "            # Progress Bar 업데이트 및 출력\n",
    "            update(loss)\n",
    "            train_progress.update(1)\n",
    "            print(f\"\\rEpoch [{epoch+1:2}/{num_epochs}], Step [{i+1:2}/{train_length}], Loss: {loss.item():.6f}\", end=\"\")\n",
    "            # print(f\"\\rEpoch [{epoch+1:2}/{num_epochs}], Step [{i+1:2}/{train_length}], Loss: {loss.item():.6f}, Domain Acc: {domain_acc:.6%}\", end=\"\")\n",
    "\n",
    "        val_acc, val_loss, val_domain_acc = 0, 0, 0\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        model.toggle_multilabel(False)\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in valid_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                domain_outputs, outputs = model(inputs)\n",
    "\n",
    "                # 분류 손실 계산\n",
    "                val_loss += criterion(outputs, targets).item() / valid_length\n",
    "                val_acc += (torch.max(outputs, 1)[1] == targets.data).sum().item() / len(valid_dataset)\n",
    "\n",
    "                # 도메인 분류기 정확도 계산\n",
    "                domain_preds = (domain_outputs >= 0.5).float()\n",
    "                domain_labels = torch.ones(inputs.size(0), 1).to(device)  # Validation 데이터는 타겟 도메인으로 가정\n",
    "                val_domain_acc += (domain_preds == domain_labels).sum().item() / domain_labels.size(0)\n",
    "\n",
    "                valid_progress.update(1)\n",
    "\n",
    "        print(f\"\\rEpoch [{epoch+1:2}/{num_epochs}], Step [{train_length}/{train_length}], Loss: {loss.item():.6f}, Valid Acc: {val_acc:.6%}, Valid Loss: {val_loss:.6f}, Domain Acc: {val_domain_acc:.6%}\", end=\"\\n\" if (epoch+1) % 5 == 0 or (epoch+1) == num_epochs else \"\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0d4c084fafa431181242fd61ffced90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/59 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c4b8cdc949040d295a9ed7f859926a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation:   0%|          | 0/15 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6746260cf2d4290a666b7d6977fe087"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4608df79053476091128415238548c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/10], Step [ 5/59], Loss: 5.127808"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 68\u001B[0m\n\u001B[1;32m     61\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# # 도메인 분류 정확도 계산\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m# domain_preds = (domain_outputs >= 0.5).float()\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# domain_acc = (domain_preds == domain_labels).sum().item() / domain_labels.size(0)\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \n\u001B[1;32m     67\u001B[0m \u001B[38;5;66;03m# Progress Bar 업데이트 및 출력\u001B[39;00m\n\u001B[0;32m---> 68\u001B[0m update(loss)\n\u001B[1;32m     69\u001B[0m train_progress\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124mEpoch [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m], Step [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_length\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m], Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.6f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[24], line 23\u001B[0m, in \u001B[0;36mcreate_plot.<locals>.update_plot\u001B[0;34m(new_loss)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_plot\u001B[39m(new_loss):\n\u001B[0;32m---> 23\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(new_loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[1;32m     24\u001B[0m     line\u001B[38;5;241m.\u001B[39mset_ydata(losses)\n\u001B[1;32m     25\u001B[0m     line\u001B[38;5;241m.\u001B[39mset_xdata(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(losses)))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "0e02f1a4",
   "metadata": {},
   "source": [
    "if not path.isdir(path.join(\".\", \"models\")):\n",
    "    mkdir(path.join(\".\", \"models\"))\n",
    "\n",
    "# Model Save\n",
    "save_path = path.join(\".\", \"models\", f\"baseline_model.pt\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a063dc95",
   "metadata": {},
   "source": "# Model Evaluation"
  },
  {
   "cell_type": "code",
   "id": "421f7090",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "model_id = \"baseline_model\"\n",
    "\n",
    "model = ImageClassifier(**MODEL_PARAMS)\n",
    "model.load_state_dict(torch.load(path.join(\".\", \"models\", f\"{model_id}.pt\")))\n",
    "model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e391d63",
   "metadata": {},
   "source": [
    "results = dict(id=[], label1=[], label2=[])\n",
    "test_length = len(test_dataset)\n",
    "\n",
    "model.eval()\n",
    "model.toggle_multilabel(True)\n",
    "with torch.no_grad():\n",
    "    for inputs, ids in tqdm(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        domain, outputs1, outputs2 = model(inputs)\n",
    "\n",
    "        # label1 처리\n",
    "        preds1 = []\n",
    "        for i in range(domain.size(0)):\n",
    "            if domain[i].item() <= 0.52:\n",
    "                preds1.append(-1)  # 도메인 분류기가 소스 도메인으로 예측하면 -1 저장\n",
    "            else:\n",
    "                # 도메인 분류기가 타겟 도메인으로 예측하면 멀티라벨 추론 수행\n",
    "                pred = torch.max(outputs2[i], 0)[1].item()\n",
    "                preds1.append(pred)\n",
    "\n",
    "        # label2는 그대로 멀티라벨 분류 결과 사용\n",
    "        preds2 = torch.max(outputs1, 1)[1]\n",
    "\n",
    "        results['id'] += [test_dataset.classes[i] for i in ids]\n",
    "        results['label1'] += preds1\n",
    "        results['label2'] += preds2.cpu().detach().numpy().tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Re-arrange Results\n",
    "for i, labels in enumerate(zip(results['label1'], results['label2'])):\n",
    "    results['label1'][i], results['label2'][i] = min(labels), max(labels)\n",
    "    # results['label1'][i], results['label2'][i] = -1, results['label1'][i]  # 멀티 라벨 분류 안하고 그냥 '-1, 라벨'로 처리\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ],
   "id": "1f8634ab05729dcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c96e7285",
   "metadata": {},
   "source": [
    "# Save Results\n",
    "submission_dir = \"submissions\"\n",
    "if not path.isdir(submission_dir):\n",
    "    mkdir(submission_dir)\n",
    "\n",
    "submit_file_path = path.join(submission_dir, f\"{model_id}.csv\")\n",
    "results_df.to_csv(submit_file_path, index=False)\n",
    "print(\"File saved to\", submit_file_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85668afc",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
