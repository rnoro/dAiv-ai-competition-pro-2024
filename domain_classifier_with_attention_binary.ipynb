{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9356e535",
   "metadata": {},
   "source": [
    "# dAiv AI_Competition[2024]_Pro Baseline for PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380b497",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "42757a94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:37.244907Z",
     "start_time": "2024-10-31T10:14:33.454521Z"
    }
   },
   "source": [
    "from os import path, rename, mkdir, listdir\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, utils, models\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datasets.utils.tqdm = tqdm\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "7e1f6fdd",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e701959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:37.925868Z",
     "start_time": "2024-10-31T10:14:37.271849Z"
    }
   },
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 31 10:14:37 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    34W / 250W |   2306MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P100-PCIE...  On   | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   41C    P0    31W / 250W |  15369MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla P100-PCIE...  On   | 00000000:07:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    28W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla P100-PCIE...  On   | 00000000:08:00.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  Tesla P100-PCIE...  On   | 00000000:0C:00.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    32W / 250W |   7941MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  Tesla P100-PCIE...  On   | 00000000:0D:00.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  Tesla P100-PCIE...  On   | 00000000:0E:00.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    32W / 250W |  13731MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  Tesla P100-PCIE...  On   | 00000000:0F:00.0 Off |                    0 |\r\n",
      "| N/A   38C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     20739      C   ...5122/anaconda3/bin/python     1627MiB |\r\n",
      "|    1   N/A  N/A      9377      C   ...on08/anaconda3/bin/python    15367MiB |\r\n",
      "|    4   N/A  N/A     24324      C   ...on08/anaconda3/bin/python     7939MiB |\r\n",
      "|    6   N/A  N/A     19590      C   ...on02/anaconda3/bin/python    13729MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "625f2443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:38.749611Z",
     "start_time": "2024-10-31T10:14:38.530804Z"
    }
   },
   "source": [
    "# Set CUDA Device Number 0~7\n",
    "DEVICE_NUM = 0\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE_NUM)\n",
    "    device = torch.device(\"cuda\")\n",
    "print(\"INFO: Using device -\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device - cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "0f54147d",
   "metadata": {},
   "source": [
    "## Load DataSets"
   ]
  },
  {
   "cell_type": "code",
   "id": "c225fe06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.231533Z",
     "start_time": "2024-10-31T10:14:38.775010Z"
    }
   },
   "source": [
    "from typing import Callable, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class ImageDataset(datasets.ImageFolder):\n",
    "    download_url = \"https://daiv-cnu.duckdns.org/contest/ai_competition[2024]_pro/dataset/archive.zip\"\n",
    "    random_state = 20241028\n",
    "\n",
    "    def __init__(\n",
    "            self, root: str, force_download: bool = True,\n",
    "            train: bool = False, valid: bool = False, split_ratio: float = 0.8,\n",
    "            test: bool = False, unlabeled: bool = False,\n",
    "            transform: Optional[Callable] = None, target_transform: Optional[Callable] = None\n",
    "    ):\n",
    "        self.download(root, force=force_download)  # Download Dataset from server\n",
    "\n",
    "        if train or valid:  # Set-up directory\n",
    "            root = path.join(root, \"train\")\n",
    "        else:\n",
    "            root = path.join(root, \"test\" if test else \"unlabeled\" if unlabeled else None)\n",
    "\n",
    "        # Initialize ImageFolder\n",
    "        super().__init__(root=root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        if train or valid:  # Split Train and Validation Set\n",
    "            seperated = train_test_split(\n",
    "                self.samples, self.targets, test_size=1-split_ratio, stratify=self.targets, random_state=self.random_state\n",
    "            )\n",
    "            self.samples, self.targets = (seperated[0], seperated[2]) if train else (seperated[1], seperated[3])\n",
    "            self.imgs = self.samples\n",
    "\n",
    "    @classmethod\n",
    "    def download(cls, root: str, force: bool = False):\n",
    "        if force or not path.isfile(path.join(root, \"archive.zip\")):\n",
    "            # Download and Extract Dataset\n",
    "            datasets.utils.download_and_extract_archive(cls.download_url, download_root=root, extract_root=root, filename=\"archive.zip\")\n",
    "            \n",
    "            # Arrange Dataset Directory\n",
    "            for target_dir in [path.join(root, \"test\"), path.join(root, \"unlabeled\")]:\n",
    "                for file in listdir(target_dir):\n",
    "                    mkdir(path.join(target_dir, file.replace(\".jpg\", \"\")))\n",
    "                    rename(path.join(target_dir, file), path.join(target_dir, file.replace(\".jpg\", \"\"), file))\n",
    "\n",
    "            print(\"INFO: Dataset archive downloaded and extracted.\")\n",
    "        else:\n",
    "            print(\"INFO: Dataset archive found in the root directory. Skipping download.\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "7536225e",
   "metadata": {},
   "source": [
    "### Dataset Initialization"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e28c116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.285884Z",
     "start_time": "2024-10-31T10:14:39.281916Z"
    }
   },
   "source": [
    "# Image Resizing and Tensor Conversion\n",
    "IMG_SIZE = (256, 256)\n",
    "IMG_NORM = dict(  # ImageNet Normalization\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "resizer = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),  # Resize Image\n",
    "    transforms.ToTensor(),  # Convert Image to Tensor\n",
    "    transforms.Normalize(**IMG_NORM)  # Normalization\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "4dabf346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.446624Z",
     "start_time": "2024-10-31T10:14:39.338972Z"
    }
   },
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "train_dataset = ImageDataset(root=DATA_ROOT, force_download=False, train=True, transform=resizer)\n",
    "valid_dataset = ImageDataset(root=DATA_ROOT, force_download=False, valid=True, transform=resizer)\n",
    "\n",
    "test_dataset = ImageDataset(root=DATA_ROOT, force_download=False, test=True, transform=resizer)\n",
    "unlabeled_dataset = ImageDataset(root=DATA_ROOT, force_download=False, unlabeled=True, transform=resizer)\n",
    "\n",
    "print(f\"INFO: Dataset loaded successfully. Number of samples - Train({len(train_dataset)}), Valid({len(valid_dataset)}), Test({len(test_dataset)}), Unlabeled({len(unlabeled_dataset)})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Dataset loaded successfully. Number of samples - Train(7478), Valid(1870), Test(1110), Unlabeled(380)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "f6562683",
   "metadata": {},
   "source": [
    "## Data Augmentation if needed"
   ]
  },
  {
   "cell_type": "code",
   "id": "219b0903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.473361Z",
     "start_time": "2024-10-31T10:14:39.469458Z"
    }
   },
   "source": [
    "augmenter = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0), ratio=(0.75, 1.333)),\n",
    "    transforms.ToTensor(),  # Convert Image to Tensor\n",
    "    transforms.Normalize(**IMG_NORM)  # Normalization\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "34f2fdb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.577355Z",
     "start_time": "2024-10-31T10:14:39.534891Z"
    }
   },
   "source": [
    "train_dataset = ImageDataset(root=DATA_ROOT, force_download=False, train=True, transform=augmenter)\n",
    "\n",
    "print(f\"INFO: Train dataset has been overridden with augmented state. Number of samples - Train({len(train_dataset)}), Unlabeled({len(unlabeled_dataset)})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Train dataset has been overridden with augmented state. Number of samples - Train(7478), Unlabeled(380)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.671654Z",
     "start_time": "2024-10-31T10:14:39.659300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unlabeled_dataset = ImageDataset(root=DATA_ROOT, force_download=False, unlabeled=True, transform=augmenter)\n",
    "\n",
    "print(f\"INFO: Unlabeled dataset has been overridden with augmented state. Number of samples - Unlabeled({len(unlabeled_dataset)})\")"
   ],
   "id": "f1d6b6f3604e3a92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Dataset archive found in the root directory. Skipping download.\n",
      "INFO: Unlabeled dataset has been overridden with augmented state. Number of samples - Unlabeled(380)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "cdb92623",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7db1579",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.774559Z",
     "start_time": "2024-10-31T10:14:39.770195Z"
    }
   },
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 128"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "a4993e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.847104Z",
     "start_time": "2024-10-31T10:14:39.838690Z"
    }
   },
   "source": [
    "MULTI_PROCESSING = True  # Set False if DataLoader is causing issues\n",
    "\n",
    "from platform import system\n",
    "if MULTI_PROCESSING and system() != \"Windows\":  # Multiprocess data loading is not supported on Windows\n",
    "    import multiprocessing\n",
    "    cpu_cores = multiprocessing.cpu_count()\n",
    "    print(f\"INFO: Number of CPU cores - {cpu_cores}\")\n",
    "else:\n",
    "    cpu_cores = 0\n",
    "    print(\"INFO: Using DataLoader without multi-processing.\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=cpu_cores)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=cpu_cores)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=cpu_cores)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=cpu_cores)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Number of CPU cores - 48\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "7a7e7658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.908599Z",
     "start_time": "2024-10-31T10:14:39.903119Z"
    }
   },
   "source": [
    "# Image Visualizer\n",
    "def imshow(image_list, mean=IMG_NORM['mean'], std=IMG_NORM['std']):\n",
    "    np_image = np.array(image_list).transpose((1, 2, 0))\n",
    "    de_norm_image = np_image * std + mean\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(de_norm_image)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "16ba9d7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.941887Z",
     "start_time": "2024-10-31T10:14:39.939112Z"
    }
   },
   "source": [
    "# images, targets = next(iter(train_loader))\n",
    "# grid_images = utils.make_grid(images, nrow=8, padding=10)\n",
    "# imshow(grid_images)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "026a5f9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:39.991305Z",
     "start_time": "2024-10-31T10:14:39.987382Z"
    }
   },
   "source": [
    "# images, _ = next(iter(unlabeled_loader))\n",
    "# grid_images = utils.make_grid(images, nrow=8, padding=10)\n",
    "# imshow(grid_images)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "11df3cce",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "f26ab8a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:40.052552Z",
     "start_time": "2024-10-31T10:14:40.043730Z"
    }
   },
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=64):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.heads = heads\n",
    "        inner_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: t.reshape(b, n, h, -1).transpose(1, 2).clone(), qkv)\n",
    "\n",
    "        # Scaled Dot-Product Attention with softmax\n",
    "        dots = (q @ k.transpose(-1, -2)) * self.scale\n",
    "        attn = dots.softmax(dim=-1).clone()  # Ensure out-of-place operation\n",
    "\n",
    "        # Attention output\n",
    "        out = (attn @ v).transpose(1, 2).reshape(b, n, -1)\n",
    "        return self.to_out(out.clone())  # Ensure out-of-place operation"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "c91befcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:40.162380Z",
     "start_time": "2024-10-31T10:14:40.156476Z"
    }
   },
   "source": [
    "class SecondMaxLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.clone()\n",
    "        max_val, max_idx = torch.max(x, dim=1, keepdim=True)\n",
    "        x.scatter_(1, max_idx, 1e-12)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "70cb1bd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:40.200848Z",
     "start_time": "2024-10-31T10:14:40.192344Z"
    }
   },
   "source": [
    "from gradient_reversal import GradientReversal\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.multiple_output = False\n",
    "\n",
    "        # 특징 추출기 (ResNet 백본)\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        self.fc_size = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(self.fc_size, hidden_size)\n",
    "        \n",
    "        # self.attention_layer = SelfAttention(hidden_size, heads=8, dim_head=64)\n",
    "\n",
    "        # 도메인 분류기 - 병목 구조 적용\n",
    "        self.domain_classifier_with_grl = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size // 4, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size // 2, 1)\n",
    "        )\n",
    "        \n",
    "        # GRL이 적용되지 않은 특징을 위한 도메인 분류기\n",
    "        self.domain_classifier_without_grl = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size // 4, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size // 2, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "        # 출력 레이어 - 최종 예측을 위한 메인 분류기\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # 멀티라벨 분류를 위한 보조 분류기 (필요할 경우 사용)\n",
    "        self.secondary = SecondMaxLayer()\n",
    "\n",
    "    def toggle_multilabel(self, multi_label: bool | None = None):\n",
    "        if isinstance(multi_label, bool):\n",
    "            self.multiple_output = multi_label\n",
    "        else:\n",
    "            self.multiple_output = not self.multiple_output\n",
    "\n",
    "    def forward(self, x, lambda_grl=1.0, return_features=False):\n",
    "        # 특징 추출\n",
    "        extracted = self.resnet(x)\n",
    "        out = self.classifier(extracted)\n",
    "    \n",
    "        # GRL 적용\n",
    "        grl_layer = GradientReversal(lambda_grl)\n",
    "        reversed_features = grl_layer(extracted)\n",
    "        domain = self.domain_classifier_with_grl(reversed_features)\n",
    "    \n",
    "        # GRL 미적용 도메인 분류기\n",
    "        detached_features = extracted.detach()\n",
    "        domain_no_grl = self.domain_classifier_without_grl(detached_features)\n",
    "    \n",
    "        if return_features:\n",
    "            # 임베딩 벡터와 함께 반환\n",
    "            return domain, domain_no_grl, out, reversed_features, detached_features\n",
    "        elif self.multiple_output:\n",
    "            # 멀티라벨 출력이 활성화된 경우\n",
    "            return domain, domain_no_grl, out, self.secondary(out)\n",
    "        else:\n",
    "            # 도메인과 메인 분류기 출력 반환\n",
    "            return domain, domain_no_grl, out"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "ceb46f93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:40.235178Z",
     "start_time": "2024-10-31T10:14:40.231574Z"
    }
   },
   "source": [
    "CLASS_LABELS = len(train_dataset.classes)\n",
    "\n",
    "MODEL_PARAMS = dict(\n",
    "    hidden_size=512, num_classes=CLASS_LABELS\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "4b7ad0cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:43.401969Z",
     "start_time": "2024-10-31T10:14:40.298713Z"
    }
   },
   "source": [
    "# Initialize Model\n",
    "model = ImageClassifier(**MODEL_PARAMS)\n",
    "model_id = 'DCwithAttention'\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared_hdd/rnoro5122/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/shared_hdd/rnoro5122/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (domain_classifier_with_grl): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (domain_classifier_without_grl): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=120, bias=True)\n",
       "  (secondary): SecondMaxLayer()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "e6c1b946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:43.446673Z",
     "start_time": "2024-10-31T10:14:43.441570Z"
    }
   },
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "35205f64",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "1f5c5a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:43.505832Z",
     "start_time": "2024-10-31T10:14:43.497727Z"
    }
   },
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Interactive Loss Plot Update\n",
    "def create_plot():\n",
    "    losses = []\n",
    "\n",
    "    # Enable Interactive Mode\n",
    "    plt.ion()\n",
    "\n",
    "    # Loss Plot Setting\n",
    "    fig, ax = plt.subplots(figsize=(6, 2))\n",
    "    line, = ax.plot(losses)\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Cross Entropy Loss\")\n",
    "\n",
    "    # Display Plot\n",
    "    plot = widgets.Output()\n",
    "    display(plot)\n",
    "\n",
    "    def update_plot(new_loss):\n",
    "        losses.append(new_loss.item())\n",
    "        line.set_ydata(losses)\n",
    "        line.set_xdata(range(len(losses)))\n",
    "        ax.relim()\n",
    "        ax.autoscale_view()\n",
    "        with plot:\n",
    "            plot.clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "    return update_plot"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "73927d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:43.545569Z",
     "start_time": "2024-10-31T10:14:43.540112Z"
    }
   },
   "source": [
    "def save_model(model_id: str, acc: float, loss: float, epoch: int | None = None) -> None:\n",
    "    dir_path: str =  path.join(\".\", \"models\", \"backup\") if epoch else path.join(\".\", \"models\")\n",
    "    if not path.isdir(dir_path):\n",
    "        mkdir(dir_path)\n",
    "    \n",
    "    if epoch:\n",
    "        model_info: str = f\"{epoch:02}__{model_id}__acc__{acc:.6f}__loss__{loss:.6f}\" \n",
    "    else: \n",
    "        model_info = f\"{model_id}__acc__{acc:.6f}__loss__{loss:.6f}\"    \n",
    "    \n",
    "    save_path: str = path.join(dir_path, f\"{model_info}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    if not epoch:\n",
    "        print(f\"Model saved to {save_path}\")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "c80d0f53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:14:43.602214Z",
     "start_time": "2024-10-31T10:14:43.598217Z"
    }
   },
   "source": [
    "# Set Epoch Count\n",
    "num_epochs = 5"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:20:22.275632Z",
     "start_time": "2024-10-31T10:14:43.654011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_length, valid_length = map(len, (train_loader, valid_loader))\n",
    "\n",
    "import itertools\n",
    "\n",
    "domain_weight = 1.0  # 도메인 손실 가중치\n",
    "domain_no_grl_weight = 1.0\n",
    "\n",
    "# 손실 함수 변경: CrossEntropyLoss -> BCEWithLogitsLoss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = tqdm(range(num_epochs), desc=\"Running Epochs\")\n",
    "with (tqdm(total=train_length, desc=\"Training\") as train_progress,\n",
    "      tqdm(total=valid_length, desc=\"Validation\") as valid_progress):  # Set up Progress Bars\n",
    "    update = create_plot()  # Create Loss Plot\n",
    "\n",
    "    for epoch in epochs:\n",
    "        train_progress.reset(total=train_length)\n",
    "        valid_progress.reset(total=valid_length)\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        model.toggle_multilabel(False)  # 멀티라벨 모드 활성화\n",
    "\n",
    "        # 무한 반복 이터레이터 생성\n",
    "        unlabeled_iter = iter(itertools.cycle(unlabeled_loader))\n",
    "\n",
    "        for i, (inputs_source, targets_source) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 소스 도메인 데이터 설정\n",
    "            inputs_source = inputs_source.to(device, non_blocking=True)\n",
    "            targets_source = targets_source.to(device, non_blocking=True)\n",
    "            domain_label_source = torch.zeros(inputs_source.size(0), 1, device=device)  # 소스 도메인 레이블: 0\n",
    "\n",
    "            # 타겟 도메인 데이터 가져오기\n",
    "            inputs_target, _ = next(unlabeled_iter)\n",
    "            inputs_target = inputs_target.to(device, non_blocking=True)\n",
    "            domain_label_target = torch.ones(inputs_target.size(0), 1, device=device)  # 타겟 도메인 레이블: 1\n",
    "\n",
    "            lambda_grl = 1.0\n",
    "\n",
    "            # 모델 출력 계산\n",
    "            # 소스 도메인 데이터에서 분류와 도메인 분류 출력\n",
    "            domain_outputs_source, domain_outputs_source_no_grl, outputs_source = model(inputs_source, lambda_grl)\n",
    "            # 타겟 도메인 데이터에서 도메인 분류 출력 (레이블 없음)\n",
    "            domain_outputs_target, domain_outputs_target_no_grl, _ = model(inputs_target, lambda_grl)\n",
    "\n",
    "            # 손실 함수 계산\n",
    "            # 분류 손실 (소스 도메인 데이터에 대해서만)\n",
    "            # 레이블 원핫 인코딩\n",
    "            num_classes = outputs_source.size(1)\n",
    "            targets_one_hot = torch.nn.functional.one_hot(targets_source, num_classes=num_classes).float()\n",
    "\n",
    "            # BCEWithLogitsLoss 사용 (sigmoid를 적용하지 않음)\n",
    "            classification_loss = criterion(outputs_source, targets_one_hot)\n",
    "\n",
    "            # 도메인 분류 손실 (소스와 타겟 도메인 모두)\n",
    "            domain_outputs = torch.cat([domain_outputs_source, domain_outputs_target], dim=0)\n",
    "            domain_outputs_no_grl = torch.cat([domain_outputs_source_no_grl, domain_outputs_target_no_grl], dim=0)\n",
    "            domain_labels = torch.cat([domain_label_source, domain_label_target], dim=0)\n",
    "\n",
    "            domain_classification_loss = criterion(domain_outputs, domain_labels)\n",
    "            domain_classification_no_grl_loss = criterion(domain_outputs_no_grl, domain_labels)\n",
    "\n",
    "            # 총 손실 계산 (분류 손실 + 가중치를 적용한 도메인 분류 손실)\n",
    "            loss = (classification_loss +\n",
    "                    domain_weight * domain_classification_loss +\n",
    "                    domain_no_grl_weight * domain_classification_no_grl_loss)\n",
    "\n",
    "            # 역전파 및 옵티마이저 스텝\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Progress Bar 업데이트 및 출력\n",
    "            update(loss)\n",
    "            train_progress.update(1)\n",
    "            print(f\"\\rEpoch [{epoch+1:2}/{num_epochs}], Step [{i+1:3}/{train_length}], Loss: {loss.item():.6f}\", end=\"\")\n",
    "\n",
    "        val_acc, val_loss, val_domain_acc, total_batches = 0, 0, 0, 0\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        model.toggle_multilabel(False)  # 멀티라벨 모드 활성화\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in valid_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                domain_outputs, domain_outputs_no_grl, outputs = model(inputs)\n",
    "\n",
    "                # 분류 손실 계산\n",
    "                # 레이블 원핫 인코딩\n",
    "                num_classes = outputs.size(1)\n",
    "                targets_one_hot = torch.nn.functional.one_hot(targets, num_classes=num_classes).float()\n",
    "\n",
    "                val_loss += criterion(outputs, targets_one_hot).item() / valid_length\n",
    "\n",
    "                # 정확도 계산 (멀티라벨 분류의 경우)\n",
    "                # 예측값에 sigmoid 적용 후 0.5 기준으로 이진화\n",
    "                predicted = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "                correct = (predicted == targets_one_hot).float().mean().item()\n",
    "                val_acc += correct / valid_length\n",
    "\n",
    "                # 도메인 분류기 정확도 계산\n",
    "                domain_preds = (torch.sigmoid(domain_outputs_no_grl) >= 0.5).float()  # 0.5 미만일 때 소스 도메인(0)으로 예측\n",
    "                domain_labels = torch.zeros(inputs.size(0), 1).to(device)  # Validation 데이터는 소스 도메인으로 가정\n",
    "                val_domain_acc += (domain_preds == domain_labels).float().mean().item() / valid_length\n",
    "\n",
    "                total_batches += 1  # 배치 수 누적\n",
    "\n",
    "                valid_progress.update(1)\n",
    "\n",
    "        # 최종 도메인 분류 정확도 계산\n",
    "        # val_domain_acc는 이미 배치 수로 평균을 냈으므로 추가로 나눌 필요 없음\n",
    "\n",
    "        print(f\"\\rEpoch [{epoch+1:2}/{num_epochs}], Step [{train_length}/{train_length}], \"\n",
    "              f\"Loss: {loss.item():.6f}, Valid Acc: {val_acc:.6%}, Valid Loss: {val_loss:.6f}, \"\n",
    "              f\"Domain Acc: {val_domain_acc:.6%}\", end=\"\\n\")\n"
   ],
   "id": "c2090e089bc1731f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e16f0f9de3641a9955552b07760325f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/59 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8b3268719874199aae33bd51ce6866d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation:   0%|          | 0/15 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5403c273f5c54d57a66a8d0e8ecff8a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b860d7d6b4c94c918fd88a1b09d21dcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/5], Step [59/59], Loss: 1.414157, Valid Acc: 99.166673%, Valid Loss: 0.046532, Domain Acc: 74.153312%\n",
      "Epoch [ 2/5], Step [59/59], Loss: 1.100067, Valid Acc: 99.166673%, Valid Loss: 0.045052, Domain Acc: 45.666400%\n",
      "Epoch [ 3/5], Step [59/59], Loss: 1.141978, Valid Acc: 99.166673%, Valid Loss: 0.047253, Domain Acc: 55.479434%\n",
      "Epoch [ 4/5], Step [59/59], Loss: 0.868100, Valid Acc: 99.166673%, Valid Loss: 0.061292, Domain Acc: 27.632212%\n",
      "Epoch [ 5/5], Step [59/59], Loss: 0.849684, Valid Acc: 99.167541%, Valid Loss: 0.055863, Domain Acc: 51.681357%\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "49f19625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:23:13.683137Z",
     "start_time": "2024-10-31T10:23:13.467868Z"
    }
   },
   "source": [
    "if not path.isdir(path.join(\".\", \"models\")):\n",
    "    mkdir(path.join(\".\", \"models\"))\n",
    "\n",
    "# Model Save\n",
    "save_path = path.join(\".\", \"models\", f\"{model_id}.pt\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./models/DCwithAttention.pt\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "8a077c3e",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9aafa53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:23:17.089566Z",
     "start_time": "2024-10-31T10:23:16.355605Z"
    }
   },
   "source": [
    "# Load Model\n",
    "model = ImageClassifier(**MODEL_PARAMS)\n",
    "model.load_state_dict(torch.load(path.join(\"./models\", f\"{model_id}.pt\")))\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48109/404286516.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path.join(\"./models\", f\"{model_id}.pt\")))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (domain_classifier_with_grl): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (domain_classifier_without_grl): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=120, bias=True)\n",
       "  (secondary): SecondMaxLayer()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "af1a1390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:27:58.242653Z",
     "start_time": "2024-10-31T10:27:51.801316Z"
    }
   },
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "results = dict(id=[], label1=[], label2=[])\n",
    "test_length = len(test_dataset)\n",
    "output_threshold = 0.5  # 출력값 임계값 설정\n",
    "domain_threshold = 0.5  # 도메인 임계값 설정\n",
    "\n",
    "model.eval()\n",
    "model.toggle_multilabel(False)  # 멀티라벨 모드 활성화\n",
    "with torch.no_grad():\n",
    "    total_single = 0\n",
    "    total_multi = 0\n",
    "    total_overflow = 0\n",
    "    for inputs, ids in tqdm(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        domain, domain_no_grl, outputs = model(inputs)\n",
    "        \n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        \n",
    "        print(outputs[0])\n",
    "\n",
    "        # 도메인 분류기 출력에 sigmoid 적용\n",
    "        domain_no_grl = torch.sigmoid(domain_no_grl)\n",
    "\n",
    "        # 출력값에 sigmoid 적용 (각 클래스에 대한 확률)\n",
    "        outputs_prob = torch.sigmoid(outputs)\n",
    "\n",
    "        # 결과 저장을 위한 리스트\n",
    "        preds1 = []\n",
    "        preds2 = []\n",
    "        for i in range(outputs_prob.size(0)):\n",
    "            # 현재 샘플의 도메인 결정\n",
    "            if domain_no_grl[i].item() <= domain_threshold:\n",
    "                # 소스 도메인: 단일 레이블 (-1)\n",
    "                preds1.append(-1)\n",
    "                # 가장 높은 확률을 가진 클래스 선택\n",
    "                pred_class = torch.argmax(outputs_prob[i]).item()\n",
    "                preds2.append(pred_class)\n",
    "                total_single += 1\n",
    "            else:\n",
    "                # 타겟 도메인: 멀티라벨 추론 수행\n",
    "                # 출력값에서 임계값 이상인 클래스 선택\n",
    "                selected_classes = (outputs_prob[i] >= output_threshold).nonzero(as_tuple=False).view(-1).tolist()\n",
    "                num_selected = len(selected_classes)\n",
    "\n",
    "                # if num_selected == 1:\n",
    "                #     # 출력값에서 1인 클래스가 1개인 경우\n",
    "                #     preds1.append(-1)\n",
    "                #     preds2.append(selected_classes[0])\n",
    "                #     total_single += 1\n",
    "                if num_selected == 2:\n",
    "                    # 출력값에서 1인 클래스가 2개인 경우\n",
    "                    preds1.append(selected_classes[0])\n",
    "                    preds2.append(selected_classes[1])\n",
    "                    total_multi += 1\n",
    "                else:\n",
    "                    # 출력값에서 1인 클래스가 3개 이상인 경우\n",
    "                    preds1.append(-3)\n",
    "                    preds2.append(-3)\n",
    "                    total_overflow += 1\n",
    "\n",
    "        results['id'] += [test_dataset.classes[i] for i in ids]\n",
    "        results['label1'] += preds1\n",
    "        results['label2'] += preds2\n",
    "\n",
    "    print(f\"Single label: {total_single}, Multi label: {total_multi}, Overflow: {total_overflow}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "653f50eae32e437eb28b6c8d7fe78c5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0593, 0.0482, 0.0329, 0.0646, 0.0707, 0.0690, 0.0359, 0.0314, 0.0627,\n",
      "        0.0324, 0.0579, 0.0445, 0.0274, 0.0518, 0.0596, 0.0426, 0.0282, 0.0408,\n",
      "        0.0449, 0.0566, 0.0367, 0.0393, 0.0506, 0.0309, 0.0333, 0.0342, 0.0385,\n",
      "        0.0522, 0.0393, 0.0488, 0.0391, 0.0382, 0.0312, 0.0406, 0.0203, 0.0316,\n",
      "        0.0333, 0.0348, 0.0372, 0.0427, 0.0316, 0.0526, 0.0314, 0.0333, 0.0328,\n",
      "        0.0311, 0.0221, 0.0437, 0.0200, 0.0394, 0.0262, 0.0466, 0.0314, 0.0335,\n",
      "        0.0256, 0.0440, 0.0300, 0.0456, 0.0408, 0.0236, 0.0421, 0.0284, 0.0383,\n",
      "        0.0297, 0.0430, 0.0267, 0.0499, 0.0216, 0.0255, 0.0353, 0.0282, 0.0340,\n",
      "        0.0379, 0.0269, 0.0284, 0.0304, 0.0569, 0.0338, 0.0327, 0.0488, 0.0267,\n",
      "        0.0347, 0.0329, 0.0297, 0.0371, 0.0442, 0.0537, 0.0272, 0.0225, 0.0292,\n",
      "        0.0327, 0.0394, 0.0299, 0.0281, 0.0287, 0.0543, 0.0201, 0.0356, 0.0395,\n",
      "        0.0293, 0.0197, 0.0293, 0.0587, 0.0528, 0.0159, 0.0317, 0.0310, 0.0467,\n",
      "        0.0264, 0.0315, 0.0245, 0.0386, 0.0540, 0.0415, 0.0478, 0.0583, 0.0404,\n",
      "        0.0461, 0.0391, 0.0262], device='cuda:0')\n",
      "tensor([0.0341, 0.0264, 0.0226, 0.0383, 0.0422, 0.0425, 0.0243, 0.0242, 0.0412,\n",
      "        0.0193, 0.0354, 0.0355, 0.0197, 0.0359, 0.0413, 0.0280, 0.0186, 0.0318,\n",
      "        0.0304, 0.0396, 0.0289, 0.0257, 0.0390, 0.0203, 0.0210, 0.0286, 0.0260,\n",
      "        0.0450, 0.0307, 0.0357, 0.0279, 0.0231, 0.0262, 0.0240, 0.0119, 0.0216,\n",
      "        0.0279, 0.0247, 0.0292, 0.0415, 0.0187, 0.0422, 0.0236, 0.0275, 0.0286,\n",
      "        0.0205, 0.0157, 0.0283, 0.0133, 0.0298, 0.0199, 0.0396, 0.0242, 0.0279,\n",
      "        0.0158, 0.0340, 0.0242, 0.0316, 0.0310, 0.0153, 0.0290, 0.0203, 0.0332,\n",
      "        0.0180, 0.0429, 0.0198, 0.0369, 0.0149, 0.0210, 0.0238, 0.0185, 0.0288,\n",
      "        0.0344, 0.0199, 0.0218, 0.0208, 0.0489, 0.0251, 0.0247, 0.0493, 0.0209,\n",
      "        0.0272, 0.0358, 0.0239, 0.0283, 0.0287, 0.0449, 0.0201, 0.0180, 0.0204,\n",
      "        0.0232, 0.0306, 0.0166, 0.0188, 0.0182, 0.0372, 0.0133, 0.0287, 0.0317,\n",
      "        0.0234, 0.0162, 0.0216, 0.0541, 0.0438, 0.0121, 0.0215, 0.0310, 0.0397,\n",
      "        0.0199, 0.0252, 0.0185, 0.0303, 0.0499, 0.0359, 0.0484, 0.0522, 0.0370,\n",
      "        0.0359, 0.0287, 0.0179], device='cuda:0')\n",
      "tensor([6.3870e-04, 6.8453e-04, 3.3631e-03, 7.3119e-05, 7.9834e-04, 5.9917e-05,\n",
      "        5.1208e-04, 1.3242e-04, 8.2756e-03, 4.1422e-04, 1.5653e-04, 3.3827e-05,\n",
      "        5.5498e-05, 3.8402e-05, 7.8519e-05, 3.5787e-05, 4.7404e-04, 2.7585e-05,\n",
      "        6.4507e-04, 9.4124e-05, 1.8271e-04, 8.6795e-05, 2.5369e-05, 1.0387e-03,\n",
      "        1.3091e-04, 6.9214e-05, 1.0613e-03, 3.1106e-05, 8.1355e-05, 2.9022e-05,\n",
      "        6.4322e-04, 4.4419e-04, 1.0905e-06, 1.8510e-05, 6.3209e-05, 5.2224e-06,\n",
      "        2.9256e-06, 8.6306e-07, 3.1294e-06, 1.4604e-06, 1.8617e-05, 3.9296e-05,\n",
      "        6.4655e-07, 1.3969e-05, 1.8928e-05, 7.5902e-05, 1.1208e-06, 1.0435e-05,\n",
      "        1.5846e-06, 5.6661e-06, 3.0588e-06, 1.5657e-06, 3.8294e-05, 9.3860e-06,\n",
      "        2.2787e-06, 9.4446e-06, 4.5899e-06, 2.6232e-05, 4.3475e-06, 1.9221e-06,\n",
      "        1.7004e-05, 1.4266e-05, 5.5615e-07, 9.2968e-05, 2.2260e-06, 2.4361e-06,\n",
      "        5.6080e-06, 1.2956e-05, 6.8029e-06, 1.0057e-06, 6.1116e-06, 8.2682e-07,\n",
      "        2.1008e-06, 5.4300e-05, 1.4792e-06, 1.5308e-06, 5.8041e-05, 6.3369e-06,\n",
      "        2.4860e-06, 2.2788e-06, 8.5000e-06, 6.2323e-06, 1.1702e-06, 1.5007e-06,\n",
      "        5.2196e-05, 7.6416e-06, 1.6942e-05, 2.1817e-06, 3.7802e-07, 7.7947e-06,\n",
      "        9.1177e-06, 8.2978e-06, 1.2232e-05, 1.1350e-05, 2.3376e-05, 2.4725e-05,\n",
      "        1.0401e-05, 1.9740e-06, 2.1182e-05, 1.5830e-06, 9.0169e-07, 1.8594e-06,\n",
      "        3.9609e-07, 7.1956e-06, 1.2846e-05, 5.2543e-06, 3.4069e-06, 5.0879e-06,\n",
      "        1.2004e-05, 3.5186e-06, 3.8164e-06, 8.2987e-06, 1.1755e-05, 1.4970e-05,\n",
      "        2.6605e-06, 1.0344e-06, 9.1857e-07, 7.6352e-06, 9.6336e-06, 1.2814e-06],\n",
      "       device='cuda:0')\n",
      "tensor([0.0522, 0.0433, 0.0232, 0.0565, 0.0569, 0.0725, 0.0270, 0.0282, 0.0494,\n",
      "        0.0225, 0.0464, 0.0433, 0.0269, 0.0465, 0.0531, 0.0372, 0.0210, 0.0380,\n",
      "        0.0400, 0.0422, 0.0306, 0.0296, 0.0425, 0.0219, 0.0274, 0.0294, 0.0240,\n",
      "        0.0523, 0.0352, 0.0437, 0.0254, 0.0294, 0.0332, 0.0298, 0.0164, 0.0262,\n",
      "        0.0265, 0.0287, 0.0312, 0.0383, 0.0259, 0.0402, 0.0248, 0.0310, 0.0258,\n",
      "        0.0227, 0.0189, 0.0339, 0.0158, 0.0321, 0.0227, 0.0463, 0.0247, 0.0281,\n",
      "        0.0214, 0.0389, 0.0245, 0.0369, 0.0353, 0.0185, 0.0305, 0.0207, 0.0326,\n",
      "        0.0241, 0.0389, 0.0243, 0.0393, 0.0173, 0.0213, 0.0276, 0.0253, 0.0294,\n",
      "        0.0339, 0.0211, 0.0262, 0.0252, 0.0460, 0.0308, 0.0265, 0.0437, 0.0230,\n",
      "        0.0281, 0.0341, 0.0260, 0.0275, 0.0350, 0.0449, 0.0215, 0.0205, 0.0255,\n",
      "        0.0275, 0.0344, 0.0224, 0.0223, 0.0222, 0.0457, 0.0171, 0.0323, 0.0365,\n",
      "        0.0253, 0.0155, 0.0248, 0.0588, 0.0487, 0.0141, 0.0276, 0.0275, 0.0370,\n",
      "        0.0220, 0.0249, 0.0199, 0.0374, 0.0476, 0.0340, 0.0463, 0.0550, 0.0398,\n",
      "        0.0354, 0.0387, 0.0237], device='cuda:0')\n",
      "tensor([0.0147, 0.0193, 0.0168, 0.0431, 0.0154, 0.0198, 0.0063, 0.0147, 0.0249,\n",
      "        0.0211, 0.0267, 0.0129, 0.0078, 0.0061, 0.0113, 0.0160, 0.0206, 0.0379,\n",
      "        0.0103, 0.0100, 0.0205, 0.0266, 0.0268, 0.0127, 0.0103, 0.0093, 0.0097,\n",
      "        0.0150, 0.0125, 0.0055, 0.0265, 0.0210, 0.0103, 0.0151, 0.0075, 0.0107,\n",
      "        0.0050, 0.0042, 0.0065, 0.0168, 0.0128, 0.0153, 0.0180, 0.0157, 0.0071,\n",
      "        0.0261, 0.0077, 0.0104, 0.0156, 0.0109, 0.0089, 0.0128, 0.0069, 0.0073,\n",
      "        0.0074, 0.0220, 0.0066, 0.0187, 0.0163, 0.0189, 0.0267, 0.0153, 0.0101,\n",
      "        0.0073, 0.0123, 0.0057, 0.0208, 0.0106, 0.0070, 0.0084, 0.0147, 0.0076,\n",
      "        0.0120, 0.0157, 0.0087, 0.0155, 0.0128, 0.0078, 0.0234, 0.0171, 0.0147,\n",
      "        0.0121, 0.0091, 0.0099, 0.0089, 0.0087, 0.0161, 0.0061, 0.0172, 0.0231,\n",
      "        0.0137, 0.0086, 0.0068, 0.0081, 0.0095, 0.0096, 0.0278, 0.0125, 0.0196,\n",
      "        0.0176, 0.0094, 0.0135, 0.0066, 0.0138, 0.0077, 0.0108, 0.0108, 0.0110,\n",
      "        0.0194, 0.0150, 0.0111, 0.0132, 0.0090, 0.0107, 0.0058, 0.0076, 0.0118,\n",
      "        0.0102, 0.0094, 0.0231], device='cuda:0')\n",
      "tensor([0.0122, 0.0165, 0.0151, 0.0374, 0.0142, 0.0172, 0.0058, 0.0122, 0.0221,\n",
      "        0.0189, 0.0240, 0.0110, 0.0065, 0.0053, 0.0093, 0.0141, 0.0159, 0.0303,\n",
      "        0.0085, 0.0083, 0.0164, 0.0226, 0.0221, 0.0119, 0.0095, 0.0079, 0.0081,\n",
      "        0.0115, 0.0117, 0.0049, 0.0213, 0.0176, 0.0082, 0.0121, 0.0059, 0.0083,\n",
      "        0.0042, 0.0037, 0.0055, 0.0148, 0.0106, 0.0136, 0.0133, 0.0123, 0.0060,\n",
      "        0.0211, 0.0063, 0.0080, 0.0127, 0.0092, 0.0075, 0.0105, 0.0061, 0.0062,\n",
      "        0.0058, 0.0183, 0.0055, 0.0156, 0.0134, 0.0143, 0.0219, 0.0130, 0.0078,\n",
      "        0.0055, 0.0097, 0.0045, 0.0159, 0.0088, 0.0063, 0.0068, 0.0116, 0.0064,\n",
      "        0.0102, 0.0128, 0.0070, 0.0126, 0.0106, 0.0063, 0.0200, 0.0147, 0.0108,\n",
      "        0.0100, 0.0072, 0.0076, 0.0075, 0.0072, 0.0135, 0.0050, 0.0136, 0.0175,\n",
      "        0.0111, 0.0069, 0.0057, 0.0065, 0.0082, 0.0078, 0.0215, 0.0104, 0.0146,\n",
      "        0.0135, 0.0076, 0.0103, 0.0053, 0.0107, 0.0063, 0.0087, 0.0083, 0.0086,\n",
      "        0.0149, 0.0118, 0.0096, 0.0108, 0.0073, 0.0090, 0.0045, 0.0060, 0.0094,\n",
      "        0.0089, 0.0076, 0.0190], device='cuda:0')\n",
      "tensor([0.0277, 0.0421, 0.0340, 0.0388, 0.0831, 0.0204, 0.0222, 0.0285, 0.0431,\n",
      "        0.0366, 0.0459, 0.0643, 0.0593, 0.0358, 0.1360, 0.1097, 0.0311, 0.0747,\n",
      "        0.0445, 0.0496, 0.0776, 0.0562, 0.0858, 0.0318, 0.0420, 0.0883, 0.0221,\n",
      "        0.0722, 0.0850, 0.1929, 0.0590, 0.0501, 0.0533, 0.0333, 0.0245, 0.0253,\n",
      "        0.0259, 0.0278, 0.0496, 0.0613, 0.0243, 0.0420, 0.0552, 0.0333, 0.0197,\n",
      "        0.0402, 0.0180, 0.0239, 0.0470, 0.0486, 0.0419, 0.0358, 0.0457, 0.0487,\n",
      "        0.0289, 0.0363, 0.0283, 0.0341, 0.0310, 0.0320, 0.0333, 0.0343, 0.0258,\n",
      "        0.0240, 0.0535, 0.0588, 0.0467, 0.0383, 0.0438, 0.0277, 0.0343, 0.0475,\n",
      "        0.0207, 0.0208, 0.0496, 0.0365, 0.0656, 0.0337, 0.0233, 0.0463, 0.0277,\n",
      "        0.0302, 0.0426, 0.0217, 0.0449, 0.0646, 0.0406, 0.0400, 0.0695, 0.0364,\n",
      "        0.0223, 0.0795, 0.0395, 0.0274, 0.0384, 0.0486, 0.0508, 0.0313, 0.0226,\n",
      "        0.0324, 0.0556, 0.0319, 0.0588, 0.0334, 0.0163, 0.0320, 0.0181, 0.0257,\n",
      "        0.0216, 0.0264, 0.0390, 0.0341, 0.0478, 0.0551, 0.0277, 0.0385, 0.0273,\n",
      "        0.0315, 0.0403, 0.0216], device='cuda:0')\n",
      "tensor([0.0453, 0.0417, 0.0325, 0.0310, 0.0536, 0.0376, 0.0438, 0.0115, 0.0692,\n",
      "        0.0269, 0.0323, 0.0147, 0.0097, 0.0187, 0.0291, 0.0136, 0.0125, 0.0075,\n",
      "        0.0212, 0.0149, 0.0137, 0.0120, 0.0153, 0.0225, 0.0226, 0.0122, 0.0197,\n",
      "        0.0127, 0.0175, 0.0173, 0.0146, 0.0234, 0.0018, 0.0074, 0.0086, 0.0039,\n",
      "        0.0044, 0.0052, 0.0053, 0.0023, 0.0100, 0.0119, 0.0024, 0.0057, 0.0062,\n",
      "        0.0099, 0.0033, 0.0070, 0.0025, 0.0052, 0.0045, 0.0056, 0.0082, 0.0045,\n",
      "        0.0039, 0.0059, 0.0034, 0.0114, 0.0055, 0.0021, 0.0083, 0.0048, 0.0029,\n",
      "        0.0079, 0.0038, 0.0033, 0.0051, 0.0071, 0.0055, 0.0031, 0.0059, 0.0029,\n",
      "        0.0047, 0.0070, 0.0034, 0.0036, 0.0104, 0.0088, 0.0029, 0.0022, 0.0028,\n",
      "        0.0045, 0.0028, 0.0032, 0.0099, 0.0054, 0.0094, 0.0038, 0.0013, 0.0057,\n",
      "        0.0042, 0.0056, 0.0069, 0.0053, 0.0109, 0.0149, 0.0062, 0.0028, 0.0081,\n",
      "        0.0026, 0.0031, 0.0036, 0.0045, 0.0061, 0.0045, 0.0034, 0.0021, 0.0058,\n",
      "        0.0060, 0.0035, 0.0041, 0.0079, 0.0098, 0.0064, 0.0061, 0.0034, 0.0029,\n",
      "        0.0036, 0.0061, 0.0024], device='cuda:0')\n",
      "tensor([0.0299, 0.0245, 0.0234, 0.0343, 0.0428, 0.0404, 0.0263, 0.0250, 0.0371,\n",
      "        0.0181, 0.0371, 0.0370, 0.0191, 0.0367, 0.0468, 0.0275, 0.0184, 0.0315,\n",
      "        0.0302, 0.0405, 0.0278, 0.0284, 0.0403, 0.0205, 0.0213, 0.0300, 0.0244,\n",
      "        0.0411, 0.0303, 0.0354, 0.0296, 0.0206, 0.0272, 0.0258, 0.0120, 0.0212,\n",
      "        0.0303, 0.0236, 0.0304, 0.0417, 0.0188, 0.0420, 0.0219, 0.0258, 0.0282,\n",
      "        0.0195, 0.0143, 0.0242, 0.0142, 0.0302, 0.0187, 0.0390, 0.0234, 0.0268,\n",
      "        0.0149, 0.0319, 0.0244, 0.0302, 0.0275, 0.0147, 0.0278, 0.0207, 0.0316,\n",
      "        0.0174, 0.0430, 0.0210, 0.0348, 0.0174, 0.0241, 0.0251, 0.0195, 0.0280,\n",
      "        0.0326, 0.0205, 0.0208, 0.0213, 0.0494, 0.0249, 0.0252, 0.0507, 0.0192,\n",
      "        0.0261, 0.0332, 0.0212, 0.0298, 0.0280, 0.0468, 0.0207, 0.0194, 0.0212,\n",
      "        0.0229, 0.0303, 0.0177, 0.0190, 0.0180, 0.0379, 0.0132, 0.0275, 0.0309,\n",
      "        0.0230, 0.0170, 0.0201, 0.0506, 0.0417, 0.0130, 0.0212, 0.0300, 0.0373,\n",
      "        0.0192, 0.0255, 0.0183, 0.0289, 0.0506, 0.0387, 0.0514, 0.0488, 0.0365,\n",
      "        0.0360, 0.0268, 0.0161], device='cuda:0')\n",
      "Single label: 681, Multi label: 0, Overflow: 429\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "779ce6b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:20:28.490368Z",
     "start_time": "2024-10-31T09:29:50.810457Z"
    }
   },
   "source": [
    "# Re-arrange Results\n",
    "for i, labels in enumerate(zip(results['label1'], results['label2'])):\n",
    "    results['label1'][i], results['label2'][i] = min(labels), max(labels)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              id  label1  label2\n",
       "0     TEST_00000      -3     116\n",
       "1     TEST_00001      -3     116\n",
       "2     TEST_00002      -3      92\n",
       "3     TEST_00003      -3      16\n",
       "4     TEST_00004      -3      81\n",
       "...          ...     ...     ...\n",
       "1105  TEST_01105      -3       2\n",
       "1106  TEST_01106      66      67\n",
       "1107  TEST_01107      -3      24\n",
       "1108  TEST_01108      -3      29\n",
       "1109  TEST_01109      21      28\n",
       "\n",
       "[1110 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>-3</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>-3</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>-3</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>-3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>-3</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>TEST_01105</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>TEST_01106</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>TEST_01107</td>\n",
       "      <td>-3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>TEST_01108</td>\n",
       "      <td>-3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>TEST_01109</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "c7ac9be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:20:28.492459Z",
     "start_time": "2024-10-31T09:29:52.688383Z"
    }
   },
   "source": [
    "# Save Results\n",
    "submission_dir = \"submissions\"\n",
    "if not path.isdir(submission_dir):\n",
    "    mkdir(submission_dir)\n",
    "\n",
    "submit_file_path = path.join(submission_dir, f\"submission.csv\")\n",
    "results_df.to_csv(submit_file_path, index=False)\n",
    "print(\"File saved to\", submit_file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to submissions/submission.csv\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:20:28.492598Z",
     "start_time": "2024-10-31T09:24:42.684200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "model.toggle_multilabel(False)\n",
    "\n",
    "# 임베딩 벡터와 레이블을 저장할 리스트 초기화\n",
    "features_with_grl = []\n",
    "features_without_grl = []\n",
    "domain_labels = []\n",
    "\n",
    "# 소스 도메인 데이터 (Validation 데이터 사용)\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in valid_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        domain_label = torch.zeros(inputs.size(0), 1)  # 소스 도메인 레이블: 0\n",
    "\n",
    "        # 모델 출력 계산 (임베딩 벡터 반환)\n",
    "        domain_outputs, domain_outputs_no_grl, outputs, reversed_features, detached_features = model(inputs, return_features=True)\n",
    "\n",
    "        # CPU로 이동하여 numpy 배열로 변환\n",
    "        reversed_features_np = reversed_features.cpu().numpy()\n",
    "        detached_features_np = detached_features.cpu().numpy()\n",
    "        domain_labels_np = domain_label.cpu().numpy()\n",
    "\n",
    "        # 리스트에 추가\n",
    "        features_with_grl.append(reversed_features_np)\n",
    "        features_without_grl.append(detached_features_np)\n",
    "        domain_labels.append(domain_labels_np)\n",
    "\n",
    "# 타겟 도메인 데이터\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in unlabeled_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        domain_label = torch.ones(inputs.size(0), 1)  # 타겟 도메인 레이블: 1\n",
    "\n",
    "        # 모델 출력 계산 (임베딩 벡터 반환)\n",
    "        domain_outputs, domain_outputs_no_grl, outputs, reversed_features, detached_features = model(inputs, return_features=True)\n",
    "\n",
    "        # CPU로 이동하여 numpy 배열로 변환\n",
    "        reversed_features_np = reversed_features.cpu().numpy()\n",
    "        detached_features_np = detached_features.cpu().numpy()\n",
    "        domain_labels_np = domain_label.cpu().numpy()\n",
    "\n",
    "        # 리스트에 추가\n",
    "        features_with_grl.append(reversed_features_np)\n",
    "        features_without_grl.append(detached_features_np)\n",
    "        domain_labels.append(domain_labels_np)\n",
    "\n",
    "# 리스트를 배열로 변환\n",
    "features_with_grl = np.concatenate(features_with_grl, axis=0)\n",
    "features_without_grl = np.concatenate(features_without_grl, axis=0)\n",
    "domain_labels = np.concatenate(domain_labels, axis=0).flatten()\n",
    "\n",
    "# 3. 차원 축소 (t-SNE 사용)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# t-SNE 모델 생성\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "# GRL이 적용된 임베딩 벡터 차원 축소\n",
    "tsne_results_with_grl = tsne.fit_transform(features_with_grl)\n",
    "\n",
    "# GRL이 적용되지 않은 임베딩 벡터 차원 축소\n",
    "tsne_results_without_grl = tsne.fit_transform(features_without_grl)\n",
    "\n",
    "# 4. 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 도메인 레이블에 따라 색상 지정\n",
    "domain_colors = ['blue' if label == 0 else 'red' for label in domain_labels]\n",
    "\n",
    "# 그림 크기 설정\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# GRL이 적용된 임베딩 벡터 시각화\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(tsne_results_with_grl[:, 0], tsne_results_with_grl[:, 1], c=domain_colors, alpha=0.5)\n",
    "plt.title('t-SNE of Embeddings with GRL')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend(handles=[plt.Line2D([], [], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Source Domain'),\n",
    "                    plt.Line2D([], [], marker='o', color='w', markerfacecolor='red', markersize=10, label='Target Domain')])\n",
    "\n",
    "# GRL이 적용되지 않은 임베딩 벡터 시각화\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(tsne_results_without_grl[:, 0], tsne_results_without_grl[:, 1], c=domain_colors, alpha=0.5)\n",
    "plt.title('t-SNE of Embeddings without GRL')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend(handles=[plt.Line2D([], [], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Source Domain'),\n",
    "                    plt.Line2D([], [], marker='o', color='w', markerfacecolor='red', markersize=10, label='Target Domain')])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "2c676a2beee99aa7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
